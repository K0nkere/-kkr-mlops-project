{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import boto3\n",
    "import pickle\n",
    "import pyarrow\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from datetime import datetime\n",
    "from dateutil.relativedelta import relativedelta\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, mean_absolute_percentage_error\n",
    "\n",
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "import mlflow\n",
    "from mlflow.tracking import MlflowClient\n",
    "from mlflow.entities import ViewType\n",
    "\n",
    "from hyperopt import STATUS_OK, Trials, fmin, hp, tpe, space_eval\n",
    "from hyperopt.pyll import scope\n",
    "\n",
    "from prefect import task, flow\n",
    "from prefect.task_runners import SequentialTaskRunner\n",
    "\n",
    "from prefect.deployments import Deployment   \n",
    "from prefect.orion.schemas.schedules import IntervalSchedule, CronSchedule\n",
    "# from prefect.flow_runners import SubprocessFlowRunner\n",
    "\n",
    "MLFLOW_TRACKING_URI = 'sqlite:///../mlops-project.db'\n",
    "\n",
    "mlflow.set_tracking_uri(\"http://127.0.0.1:5000/\")\n",
    "mlflow_client = MlflowClient(tracking_uri = MLFLOW_TRACKING_URI)\n",
    "BUCKET = 'kkr-mlops-zoomcamp'\n",
    "\n",
    "def read_file(key, bucket=BUCKET):\n",
    "\n",
    "    session = boto3.session.Session()\n",
    "    s3 = session.client(\n",
    "        service_name='s3',\n",
    "        endpoint_url='https://storage.yandexcloud.net',\n",
    "        region_name='ru-central1',\n",
    "        # aws_access_key_id = \"id\",\n",
    "        # aws_secret_access_key = \"key\")\n",
    "    )\n",
    "    obj = s3.get_object(Bucket=bucket, Key=key)\n",
    "\n",
    "    data = pd.read_csv(obj['Body'], sep=\",\")\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "@task\n",
    "def load_data(current_date = \"2015-5-17\", periods = 1):\n",
    "    \n",
    "    dt_current = datetime.strptime(current_date, \"%Y-%m-%d\")\n",
    "    \n",
    "    if periods == 1:\n",
    "        date_file = dt_current + relativedelta(months = - 1)\n",
    "        print(f\"Getting TEST data for {date_file.year}-{date_file.month} period\")\n",
    "        test_data = read_file(key = f\"datasets/car-prices-{date_file.year}-{date_file.month}.csv\")\n",
    "\n",
    "        return test_data\n",
    "\n",
    "    else:\n",
    "        train_data = pd.DataFrame()\n",
    "        for i in range(periods+1, 1, -1):\n",
    "            date_file = dt_current + relativedelta(months = - i)\n",
    "            try:\n",
    "                data = read_file(key = f\"datasets/car-prices-{date_file.year}-{date_file.month}.csv\")\n",
    "                print(f\"Getting TRAIN data for {date_file.year}-{date_file.month} period\")\n",
    "            except:\n",
    "                print(f\"Cannot find file car-prices-{date_file.year}-{date_file.month}.csv\",\n",
    "                    \"using blank\")\n",
    "                data = None\n",
    "                \n",
    "            train_data = pd.concat([train_data, data])\n",
    "        \n",
    "        return train_data\n",
    "\n",
    "\n",
    "@task\n",
    "def na_filter(data):\n",
    "    work_data = data.copy()\n",
    "    non_type = work_data[data['make'].isna() | data['model'].isna() | data['trim'].isna()].index\n",
    "    work_data.drop(non_type, axis=0, inplace=True)\n",
    "\n",
    "    y = work_data.pop('sellingprice')\n",
    "\n",
    "    return work_data, y\n",
    "\n",
    "\n",
    "class FeaturesModifier:\n",
    "    def __init__(self, columns):\n",
    "        self.columns = columns\n",
    "\n",
    "    def fit(self, work_data, _ = None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, work_data, _ = None):\n",
    "\n",
    "        work_data = pd.DataFrame(work_data, columns = self.columns)\n",
    "        work_data['make_model_trim'] = work_data['make'] + '_'  + work_data['model'] + '_' + work_data['trim']\n",
    "        work_data['year'] = work_data['year'].astype('str')\n",
    "        \n",
    "        cat_cols = ['year', 'make_model_trim', 'body', 'transmission', 'color', 'interior']\n",
    "        num_cols = ['condition', 'odometer', 'mmr']\n",
    "\n",
    "        X = work_data[cat_cols + num_cols].copy()\n",
    "        X_dict = X.to_dict(orient = 'records')\n",
    "\n",
    "        return X_dict\n",
    "\n",
    "    def fit_transform(self, work_data, _ = None):\n",
    "        return self.transform(work_data)\n",
    "\n",
    "\n",
    "@task\n",
    "def prepare_features(work_data, preprocessor = None):\n",
    "\n",
    "    num_2_impute = ['condition', 'odometer', 'mmr']\n",
    "    cat_2_impute = ['body', 'transmission']\n",
    "    constant_2_impute = ['color', 'interior']\n",
    "    others = ['year', 'make', 'model', 'trim']\n",
    "    \n",
    "    if not preprocessor:\n",
    "        features_filler = ColumnTransformer([\n",
    "            ('num_imputer', SimpleImputer(missing_values=np.nan, strategy='mean'), num_2_impute),\n",
    "            ('cat_imputer', SimpleImputer(missing_values=np.nan, strategy='most_frequent'), cat_2_impute),\n",
    "            ('cat_constant', SimpleImputer(missing_values=np.nan, strategy='most_frequent'), constant_2_impute),\n",
    "            ('others', SimpleImputer(missing_values=np.nan, strategy='constant', fill_value='-1'), others )\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        fm = FeaturesModifier(columns = num_2_impute + cat_2_impute + constant_2_impute + others)\n",
    "\n",
    "        dv = DictVectorizer() \n",
    "\n",
    "        preprocessor = Pipeline(steps = [\n",
    "            ('filler', features_filler),\n",
    "            ('modifier', fm),\n",
    "            ('dict_vectorizer', dv)\n",
    "        ])\n",
    "        \n",
    "        X = preprocessor.fit_transform(work_data)\n",
    "\n",
    "    else:\n",
    "        X = preprocessor.transform(work_data)\n",
    "\n",
    "    return X, preprocessor\n",
    "\n",
    "\n",
    "@task\n",
    "def params_search(train, valid, y_train, y_valid, train_dataset_period, models):\n",
    "    \n",
    "    # mlflow.set_tracking_uri(MLFLOW_TRACKING_URI)\n",
    "\n",
    "    best_models = []\n",
    "\n",
    "    for baseline in models:\n",
    "        \n",
    "        mlflow.set_experiment(f\"{baseline.__name__}-models\")\n",
    "        search_space = models[baseline]\n",
    "\n",
    "        def objective(params):\n",
    "\n",
    "            with mlflow.start_run():\n",
    "                mlflow.set_tag(\"baseline\", f\"{baseline.__name__}\")\n",
    "                mlflow.log_param(\"train_dataset\", train_dataset_period)\n",
    "                mlflow.log_param(\"parameters\", params)\n",
    "                \n",
    "                print('$$$ Serching for the best parameters... $$$')\n",
    "\n",
    "                training_model = baseline(**params)\n",
    "                training_model.fit(train, y_train)\n",
    "\n",
    "                print('$$$ Predicting on the valid dataset... $$$')\n",
    "                prediction_valid = training_model.predict(valid)\n",
    "                rmse_valid = mean_squared_error(y_valid, prediction_valid, squared = False)\n",
    "                mae_valid = mean_absolute_error(y_valid, prediction_valid)\n",
    "                mape_valid = mean_absolute_percentage_error(y_valid, prediction_valid)\n",
    "\n",
    "                print(f'$$$ Errors on valid: RMSE {rmse_valid} MAE {mae_valid} MAPE {mape_valid} $$$', )\n",
    "                mlflow.log_metric('rmse_valid', rmse_valid)\n",
    "                mlflow.log_metric('mae_valid', mae_valid)\n",
    "                mlflow.log_metric('mape_valid', mape_valid)\n",
    "\n",
    "            return {'loss': rmse_valid, 'status': STATUS_OK}\n",
    "        \n",
    "        best_result = fmin(fn = objective,\n",
    "                    space = search_space,\n",
    "                    algo = tpe.suggest,\n",
    "                    max_evals = 2, # int(2**(len(models[baseline].items())-2)), #3,\n",
    "                    trials = Trials(),\n",
    "                    ) \n",
    "        \n",
    "        print(\"$$$ Best model $$$\\n\", baseline(**space_eval(search_space, best_result)))\n",
    "        best_models.append(baseline(**space_eval(search_space, best_result)))\n",
    "\n",
    "        mlflow.end_run()\n",
    "    \n",
    "    return best_models\n",
    "\n",
    "\n",
    "#  @task\n",
    "def train_best_models(best_models_experiment, train, y_train, X_valid, y_valid, X_test, y_test, preprocessor, models, train_dataset_period):\n",
    "\n",
    "    # mlflow.set_tracking_uri(MLFLOW_TRACKING_URI)\n",
    "    # mlflow_client = MlflowClient(tracking_uri = MLFLOW_TRACKING_URI)\n",
    "\n",
    "    best_pipelines = []\n",
    "    test_dataset_period = X_test[\"saledate\"].max()[:7]\n",
    "    query = f'parameters.train_dataset = \"{train_dataset_period}\"'\n",
    "\n",
    "    mlflow.autolog()\n",
    "    for model in models:\n",
    "    \n",
    "        experiment = mlflow.set_experiment(f\"{model.__name__}-models\")\n",
    "\n",
    "        best_run = mlflow_client.search_runs(\n",
    "                experiment_ids = experiment.experiment_id,\n",
    "                run_view_type=ViewType.ACTIVE_ONLY,\n",
    "                max_results = 2,\n",
    "                filter_string=query,\n",
    "                order_by = ['metrics.rmse_valid ASC']\n",
    "            )\n",
    "        \n",
    "        print(f\"$$$ Training {model.__name__} with best params $$$\")\n",
    "\n",
    "        mlflow.set_experiment(best_models_experiment) #\"Auction-car-prices-best-models\")\n",
    "    \n",
    "        with mlflow.start_run():\n",
    "            \n",
    "            mlflow.log_param(\"test_dataset\", test_dataset_period)\n",
    "\n",
    "            best_params = json.loads(best_run[0].data.params['parameters'].replace(\"'\", \"\\\"\"))\n",
    "            staged_model = model(**best_params).fit(train, y_train)\n",
    "            \n",
    "            pipeline = Pipeline(\n",
    "                steps = [\n",
    "                    ('preprocessor', preprocessor),\n",
    "                    ('model', staged_model)\n",
    "                ]\n",
    "            )\n",
    "            predict_valid = pipeline.predict(X_valid)\n",
    "            rmse_valid = mean_squared_error(y_valid, predict_valid, squared = False)\n",
    "\n",
    "            predict_test = pipeline.predict(X_test)\n",
    "            rmse_test = mean_squared_error(y_test, predict_test, squared = False)\n",
    "            mae_test = mean_absolute_error(y_test, predict_test)\n",
    "            mape_test = mean_absolute_percentage_error(y_test, predict_test)\n",
    "\n",
    "            mlflow.log_metric(\"rmse_valid\", rmse_valid)\n",
    "            mlflow.log_metric(\"rmse_test\", rmse_test)\n",
    "            mlflow.log_metric('mae_test', mae_test)\n",
    "            mlflow.log_metric('mape_test', mape_test)\n",
    "            mlflow.sklearn.log_model(pipeline, artifact_path='full-pipeline')\n",
    "            \n",
    "            best_pipelines.append((model.__name__, pipeline))\n",
    "\n",
    "            print(\"$$$ {:} MODEL was saved as a RUN of {:} $$$\".format(model.__name__, best_models_experiment))\n",
    "\n",
    "            mlflow.end_run()\n",
    "\n",
    "    return best_pipelines\n",
    "\n",
    "\n",
    "#  @task\n",
    "def model_to_registry(best_models_experiment, model_name, test_dataset_period):\n",
    "\n",
    "    # mlflow.set_tracking_uri(MLFLOW_TRACKING_URI)\n",
    "    # mlflow_client = MlflowClient(tracking_uri = MLFLOW_TRACKING_URI)\n",
    "    \n",
    "    experiment = mlflow.set_experiment(best_models_experiment) #'Auction-car-prices-best-models')\n",
    "\n",
    "    query = f'parameters.test_dataset = \"{test_dataset_period}\"'\n",
    "    best_model_run = mlflow_client.search_runs(\n",
    "        experiment_ids=experiment.experiment_id,\n",
    "        run_view_type=ViewType.ACTIVE_ONLY,\n",
    "        filter_string=query,\n",
    "        max_results=1,\n",
    "        order_by=[\"metrics.rmse_test ASC\"]\n",
    "            \n",
    "        )\n",
    "    RUN_ID = best_model_run[0].info.run_id\n",
    "    model_uri = \"runs:/{:}/full-pipeline\".format(RUN_ID)\n",
    "   \n",
    "    print(f\"$$$ Registering model {model_name} $$$\")\n",
    "    registered_model = mlflow.register_model(\n",
    "            model_uri=model_uri,\n",
    "            name = model_name\n",
    "        )\n",
    "    print(f\"$$$ Model RUN_ID {registered_model.run_id} was registered as version {registered_model.version} at {registered_model.current_stage} stage $$$\")\n",
    "    \n",
    "    return registered_model\n",
    "\n",
    "\n",
    "#  @task\n",
    "def model_promotion(current_date, model_name, registered_model_version, to_stage):\n",
    "\n",
    "    # mlflow.set_tracking_uri(MLFLOW_TRACKING_URI)\n",
    "    # mlflow_client = MlflowClient(tracking_uri = MLFLOW_TRACKING_URI)\n",
    "\n",
    "    promoted_model = mlflow_client.transition_model_version_stage(\n",
    "                                name = model_name,\n",
    "                                version = registered_model_version,\n",
    "                                stage = to_stage,\n",
    "                                archive_existing_versions=True\n",
    "                                )\n",
    "\n",
    "    mlflow_client.update_model_version(\n",
    "        name = model_name,\n",
    "        version = registered_model_version,\n",
    "        description=f'The model was promoted to {to_stage} {current_date}'\n",
    "        )\n",
    "    print(f\"$$$ Model {model_name} version {registered_model_version} was promoted to {to_stage} {current_date} $$$\")\n",
    "\n",
    "    return promoted_model\n",
    "\n",
    "\n",
    "def load_model(model_name, stage=None, version=None, run_id=None):\n",
    "    \n",
    "    # mlflow_client = MlflowClient(MLFLOW_TRACKING_URI)\n",
    "    # mlflow.set_tracking_uri(MLFLOW_TRACKING_URI)\n",
    "\n",
    "    versions = mlflow_client.get_latest_versions(\n",
    "                name=model_name,\n",
    "                stages=[stage]\n",
    "                )\n",
    "\n",
    "    try:\n",
    "        model_uri = f\"models:/{model_name}/{versions[0].current_stage}\"\n",
    "        model = mlflow.pyfunc.load_model(model_uri = model_uri)\n",
    "\n",
    "        return model, versions[0].version\n",
    "    except:\n",
    "        print(f\"$$$ There are no models at {stage} stage\")\n",
    "        \n",
    "        return None, None\n",
    "\n",
    "\n",
    "#  @task\n",
    "def switch_model_of_production(X_test, y_test, model_name): #, current_date):\n",
    "    \n",
    "    # mlflow.set_tracking_uri(\"http://127.0.0.1:5000/\")\n",
    "    # mlflow.set_tracking_uri(MLFLOW_TRACKING_URI)\n",
    "    # mlflow_client = MlflowClient(MLFLOW_TRACKING_URI)\n",
    "\n",
    "    staging_model, staging_version = load_model(model_name, stage = \"Staging\")\n",
    "    if staging_model:\n",
    "        staging_test_prediction = staging_model.predict(X_test)\n",
    "        rmse_staging = mean_squared_error(staging_test_prediction, y_test, squared=False)\n",
    "        print(staging_version, rmse_staging)\n",
    "    else:\n",
    "        rmse_staging = np.inf\n",
    "\n",
    "    production_model, production_version = load_model(model_name, stage = \"Production\")\n",
    "    if production_model:\n",
    "        production_test_prediction = production_model.predict(X_test)\n",
    "        rmse_production = mean_squared_error(production_test_prediction, y_test, squared=False)\n",
    "        print(production_version, rmse_production)\n",
    "\n",
    "    else:\n",
    "        rmse_production = np.inf\n",
    "\n",
    "    if rmse_staging <= rmse_production:\n",
    "        print(f\"$$$ Need to switch models. Version {staging_version} is better than {production_version} $$$\")\n",
    "        return staging_version\n",
    "        \n",
    "    else:\n",
    "        print(f\"$$$ No need to switch models. Version {production_version} is the best $$$\")\n",
    "        return None\n",
    "\n",
    "\n",
    "@flow(task_runner = SequentialTaskRunner())\n",
    "def main(current_date = \"2015-7-21\", periods = 5):\n",
    "    \n",
    "    best_models_experiment = \"Auction-car-prices-best-models\"\n",
    "    model_name = \"Auction-car-prices-prediction\"\n",
    "\n",
    "    train_data = load_data(current_date = current_date, periods = periods)\n",
    "    X, y = na_filter(train_data)\n",
    "\n",
    "    test_data = load_data(current_date = current_date)\n",
    "    X_test, y_test = na_filter(test_data)\n",
    "\n",
    "    train_dataset_period = X[\"saledate\"].max()[:7]\n",
    "    test_dataset_period = X_test[\"saledate\"].max()[:7]\n",
    "\n",
    "    X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "\n",
    "    print(\"$$$ Training preprocessor... $$$\")\n",
    "    train, preprocessor = prepare_features(X_train, preprocessor = None )\n",
    "    valid, _  = prepare_features(X_valid, preprocessor)\n",
    "\n",
    "    print(\"$$$ Initializing parameters for baseline models... $$$\")\n",
    "    models = {\n",
    "        LinearRegression: {\n",
    "            \"fit_intercept\": hp.choice(\"fit_intercept\", ('True', 'False'))\n",
    "            },\n",
    "        Ridge: {\"alpha\": hp.loguniform(\"alpha\", -5, 5),\n",
    "                \"fit_intercept\": hp.choice(\"fit_intercept\", ('True', 'False'))\n",
    "            },\n",
    "        # RandomForestRegressor: {\n",
    "        #         'max_depth': scope.int(hp.quniform('max_depth', 1, 20, 1)),\n",
    "        #         'n_estimators': scope.int(hp.quniform('n_estimators', 10, 50, 1)),\n",
    "        #         'min_samples_split': scope.int(hp.quniform('min_samples_split', 2, 10, 1)),\n",
    "        #         'min_samples_leaf': scope.int(hp.quniform('min_samples_leaf', 1, 4, 1)),\n",
    "        #         'random_state': 42\n",
    "        #         },\n",
    "        # XGBRegressor: {\n",
    "        #         'max_depth': scope.int(hp.quniform('max_depth', 4, 100, 1)),\n",
    "        #         'learning_rate': hp.loguniform('learning_rate', -3, 0),\n",
    "        #         'reg_alpha': hp.loguniform('reg_alpha', -5, -1),\n",
    "        #         'reg_lambda': hp.loguniform('reg_lambda', -6, -1),\n",
    "        #         'max_child_weight': hp.loguniform('max_child_weight', -1, 3),\n",
    "        #         'num_boost_rounds': 100,\n",
    "        #         # 'early_stopping_rounds': 20,\n",
    "        #         'objective': 'reg:squarederror',\n",
    "        #         'seed': 42,\n",
    "        #         }\n",
    "        }\n",
    "\n",
    "    best_models = params_search(\n",
    "        train, valid,\n",
    "        y_train, y_valid,\n",
    "        train_dataset_period,\n",
    "        models)\n",
    "\n",
    "    # print(\"$$$ Best params $$$\\n\", best_models)\n",
    "\n",
    "    best_pipelines = train_best_models(\n",
    "        best_models_experiment,\n",
    "        train, y_train,\n",
    "        X_valid, y_valid,\n",
    "        X_test, y_test,\n",
    "        preprocessor,\n",
    "        models,\n",
    "        train_dataset_period\n",
    "        )\n",
    "\n",
    "    registered_model = model_to_registry(best_models_experiment, model_name, test_dataset_period)\n",
    "    # print(registered_model.run_id, registered_model.version)\n",
    "\n",
    "    model_promotion(\n",
    "        current_date,\n",
    "        model_name,\n",
    "        registered_model_version=registered_model.version,\n",
    "        to_stage = \"Staging\"\n",
    "        )\n",
    "\n",
    "    switch_to_version = switch_model_of_production(X_test, y_test, model_name) #, current_date)\n",
    "\n",
    "    if switch_to_version:\n",
    "        model_promotion(\n",
    "            current_date = current_date,\n",
    "            model_name = model_name,\n",
    "            registered_model_version = switch_to_version,\n",
    "            to_stage=\"Production\"\n",
    "            )\n",
    "    else:\n",
    "        print(\"$$$ Current is OK $$$\")\n",
    "\n",
    "main()\n",
    "# Deployment(flow = main,\n",
    "#                 name = 'MLOps-project-auction-car-prices',\n",
    "#                 schedule = IntervalSchedule(interval = timedelta(minutes=5)), \n",
    "#                 flow_runner = SubprocessFlowRunner(),\n",
    "#                 tags = ['ml-cpu'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"Auction-car-prices-prediction\"\n",
    "stage = 'Production'\n",
    "run_id = \"9c07c4e0556746a89adee76fe681290d\"\n",
    "\n",
    "production_model = mlflow.pyfunc.load_model(model_uri=f'models:/{model_name}/{stage}')\n",
    "# production_model = mlflow.pyfunc.load_model(model_uri=f'runs:/{run_id}/model/')\n",
    "\n",
    "print(production_model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('mlops-project-env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "cc061999a195cafdfc0c6b661fb63207179de77be5d05593043c5b89d9b39722"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
